{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd261583-9a95-427d-ac5a-843f0d552bc5",
   "metadata": {},
   "source": [
    "This notebook is a handler to inspect GeoCODES schema.org metadata, conforming to ESIP Science On Schema.org conventions\n",
    "Notebook is set up with these parameters from the GeoCODES UI: \n",
    "    url-- the contentURL from the distribution\n",
    "    ext -- the schema:encodingFormat from the distribution metadata; defaults to NONE if no value passed,\n",
    "First acquire the distribution file and checking that it can be read, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ab37d00-8c17-4feb-a006-84d9a7ff7578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#github.com/nteract/papermill'parameters'tag used to inject them into template then post a gist runable by colab\n",
    "url,ext,urn=None,None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b52a71-02e9-45ef-9791-939e5ab16d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# these are the parameters passed from the GeoCodes Searth interface\n",
    "# the schema:distribution download URL. This should be a content URL\n",
    "\n",
    "url = \"https://www.hydroshare.org/hsapi/resource/b541f44606a44a4a911e0e09d1b88d74\"\n",
    "ext = \"application/zip\"\n",
    "urn = \"urn:gleaner:milled:hydroshare:9ebedd91635b1a39160afcac44ecf3ccd2d22794\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2426a355-4e02-43b7-b8ad-53dbf8a2b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install httpimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d5d3e8-a523-4e74-b901-dd0ffa253067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df=can not read zip w/o knowing what is in it, doing:[!wget $url ],to see:[ !ls -l ]size:None or FileExplorerPane on the left[Warn:No File]\n",
      "response status=200, headers: application/zip, formatmatch: True\n"
     ]
    }
   ],
   "source": [
    "import httpimport\n",
    "import requests\n",
    "import pandas\n",
    "with httpimport.github_repo('earthcube', 'earthcube_utilities'):\n",
    "    import earthcube_utilities as ec\n",
    "\n",
    "ec.wget_rdf(urn)\n",
    "#!ls -l   or FilePaneBrowser on left, to see it\n",
    "df=ec.read_file(url,ext)\n",
    "print (f'df={df}')\n",
    "\n",
    "response = requests.get(url)\n",
    "tcode = response.status_code\n",
    "\n",
    "theheaders = response.headers['content-type']\n",
    "\n",
    "formatMatch = False\n",
    "if theheaders != None and ext != None and theheaders in ext:\n",
    "    formatMatch = True\n",
    "\n",
    "\n",
    "print (f'response status={tcode}, headers: {theheaders}, formatmatch: {formatMatch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3bfa7b7-5c05-413c-a830-e5894f8fdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************** DISPATCH ****************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ddae9d-46b4-452c-bed4-a2601d68a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of ZIP archive: \n",
      "\n",
      "mainriversites.dbf\n",
      "mainriversites_meta.xml\n",
      "mainriversites.prj\n",
      "mainriversites_resmap.xml\n",
      "mainriversites.sbn\n",
      "mainriversites.sbx\n",
      "mainriversites.shp\n",
      "mainriversites.shx\n",
      "resourcemap.xml\n",
      "resourcemetadata.xml\n",
      "bagit.txt\n",
      "manifest-md5.txt\n",
      "readme.txt\n",
      "tagmanifest-md5.txt\n"
     ]
    }
   ],
   "source": [
    "# ****************** ZIP ARCHIVE ******************\n",
    "#anything that has a response content header for a zip archive\n",
    "# TBD look at ext for specific kinds of zip archives that can be processed in more interesting ways\n",
    "if 'application/zip' in theheaders:\n",
    "  import zipfile   \n",
    "  with open('test.zip', 'wb') as fd:\n",
    "    for chunk in response.iter_content(chunk_size=128):\n",
    "        fd.write(chunk)\n",
    "    fd.close\n",
    "  with zipfile.ZipFile('test.zip','r') as myzip:\n",
    "    thefiles = myzip.namelist()\n",
    "  print ('Contents of ZIP archive: \\n')\n",
    "  for fname in thefiles:\n",
    "    print (ec.path_leaf(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369ef2f7-e730-43c9-b2f3-76b1b420d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************** MagIC tsv database file *********************\n",
    "#do something with MagIC tsv database files\n",
    "\n",
    "if 'earthref-tsv' in ext.lower():\n",
    "    print ('MagIC file')\n",
    "    import operations.magic.MagicToDataFrames as magic\n",
    "    resultframedict = magic.magicToDataframe(txt=response.text)\n",
    "    \n",
    "    if not(resultframedict['contribution'].empty):\n",
    "        thecontribs=resultframedict['contribution']\n",
    "        thekeys=(list(thecontribs))\n",
    "        for index, row in thecontribs.iterrows():\n",
    "            if 'contributor' in thekeys:\n",
    "                contrib = 'contributor: ' + row['contributor'] + '; \\n'\n",
    "            else:\n",
    "                contrib = ''\n",
    "            if 'author' in thekeys:\n",
    "                auth = 'author: ' + row['author'] + '; \\n'\n",
    "            else:\n",
    "                auth = ''\n",
    "\n",
    "            if 'reference' in thekeys:\n",
    "                refer = 'reference: ' + row['reference'] + '; \\n'\n",
    "            else:\n",
    "                refer = ''\n",
    "\n",
    "            if 'data_model_version' in thekeys:\n",
    "                dm = 'data_model_version: ' + row['data_model_version'] + ';'\n",
    "            else:\n",
    "                dm = ''\n",
    "\n",
    "            print(contrib  + auth  +  refer  + dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c845ef9c-7451-4425-97d6-88773a4cf756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************** NetCDF File **********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18fc11e6-c1f4-471b-a145-fb6703d9f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urn:gleaner:milled:hydroshare:57d631b8ca18b4378ad4db0b9271ebca88311b53\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "thegraph=ec.wget_rdf(urn)\n",
    "print (urn)\n",
    "print (thegraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc81cca-88ce-43e9-903d-570ef045c0bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20404/3736636361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthegraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#shows .nt metadata from urn, can use for (rdf)xml as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Workspace\\GithubC\\earthcube\\earthcube_utilities\\earthcube_utilities.py\u001b[0m in \u001b[0;36mviz\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".all.nt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#might call this rdf_viz once we get some other type of viz going\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mhas_ext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[0mext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_ext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0mfnb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#unused, bc they should strip the ext anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Workspace\\GithubC\\earthcube\\earthcube_utilities\\earthcube_utilities.py\u001b[0m in \u001b[0;36mhas_ext\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhas_ext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mfile_base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Workspace\\GithubC\\earthcube\\earthcube_utilities\\earthcube_utilities.py\u001b[0m in \u001b[0;36mfile_base\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfile_base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0madd2log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'fb:st={st}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\GeoCodes\\lib\\ntpath.py\u001b[0m in \u001b[0;36msplitext\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgenericpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_splitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "ec.viz(thegraph) #shows .nt metadata from urn, can use for (rdf)xml as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe07dc-9eba-40da-a2b3-83491ee654d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
