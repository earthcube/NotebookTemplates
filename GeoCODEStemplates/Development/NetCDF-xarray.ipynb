{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inspecting NetCDF data using xarray\n",
    "\n",
    "This notebook provides some basic examples on opening a NetCDF dataset using the xarray package.  Many of the cells will need to be updated with variable names from the dataset you ar inspecting, and are commented out. Substitute appropriate variable, coordinate, or attribute names where appropriate and uncomment to run the cells.\n",
    "\n",
    "This notebook is based on an excellent tutorial notebook by Kristen Thyng and Rob Hetland in their [python4geosciences github repository](https://github.com/kthyng/python4geosciences).  See also [this xarray tutorial by Anderson Banihirwe](https://github.com/andersy005/xarray-tutorial), and on [YouTube](https://www.youtube.com/watch?v=Ss4ryKukhi4&t=145s)\n",
    "\n",
    "\n",
    "`xarray` expands the utility of the time series analysis package `pandas` into more than one dimension. It is actively being developed in conjunction with many other packages under the [Pangeo](https://pangeo.io/) umbrella. For example, you can run with Dask to use multiple cores on your laptop when you are working with data read in with `xarray`.\n",
    "\n",
    "NetCDF is a binary storage format for many different kinds of rectangular data. Examples include atmosphere and ocean model output, satellite images, and timeseries data. NetCDF files are intended to be device independent, and the dataset may be queried in a fast, random-access way. More information about NetCDF files can be found [here](http://www.unidata.ucar.edu/software/netcdf/). The [CF conventions](http://cfconventions.org) are used for storing NetCDF data for earth system models, so that programs can be aware of the coordinate axes used by the data cubes.\n",
    "\n",
    "We will read the netCDF file using `xarray`\n",
    "\n",
    "This template works with datasets that have schema.org metadata registered with the EarthCube GeoCODES catalog, and have a valid URL Dataset/distribution/contentURL with an associated ./encodingFormat value of 'application/x-netcdf'. This is a fall-through demonstration for NetCDF encoded datasets that do not self-identify in the metadata as conforming to a more specific NetCDF profile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#github.com/nteract/papermill'parameters'tag used to inject them into template then post a gist runable by colab\n",
    "url,ext,urn=None,None,None\n",
    "\n",
    "# Parameters\n",
    "# these parameters are passed from the GeoCodes Searth interface; \n",
    "# assign default values:\n",
    "#url = \"http://cmore.soest.hawaii.edu/cmoredata/Doney/3D/CMORE_NPAC_BEC.gx3.22.anthro.cv2.1959.nc\"\n",
    "url = \"http://cmore.soest.hawaii.edu/cmoredata/Doney/3D/CMORE_NPAC_BEC.gx3.22.anthro.cv2.1982.nc\"\n",
    "ext = \"\"\n",
    "urn = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cartopy\n",
    "#import cmocean.cm as cmo\n",
    "import pandas as pd\n",
    "import requests \n",
    "import xarray as xr\n",
    "import cftime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testurl(theurl):\n",
    "    #try HEAD first in case the response document is big\n",
    "    r = requests.head(theurl)\n",
    "    if (r.status_code != requests.codes.ok):\n",
    "        #check GET in case is an incomplete http implementation\n",
    "        r = requests.get(theurl, stream=True)\n",
    "        print('content size:', r.headers['content-length'])\n",
    "        if (r.status_code == requests.codes.ok):\n",
    "            return True\n",
    "        else:\n",
    "            print ('status code: ', r.status_code)\n",
    "            return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file-like object with .nc extension from the URL\n",
    "\n",
    "if testurl(url):\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    open('temp.nc', 'wb').write(response.content)\n",
    "else:\n",
    "    print('url ', url, 'not responding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open dataset\n",
    "We'll use the `xarray` package to read this file, which has already been saved into the `data` directory.\n",
    "\n",
    "One of the useful things about `xarray` is that it doesn't deal with the numbers in the file until it has to. This is called \"lazy evaluation\". It will note the operations you want done, but won't actually perform them until it needs to spit out numbers.\n",
    "\n",
    "Viewing metadata is instantaneous since no calculations need to be done, even if the file is huge.\n",
    "\n",
    "An xarray data object is a \"dataset\" or \"data array\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('temp.nc',decode_times=False)\n",
    "\n",
    "# look at overview of metadata for file\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables that are in our dataset\n",
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dimensions\n",
    "ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset coordinates\n",
    "ds.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset global attributes\n",
    "ds.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at shape and units for a variable\n",
    "# copy in a variable name for {varname}\n",
    "# ds.{varname}.shape, ds.{varname}.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the metadata\n",
    "ds.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract numbers\n",
    "\n",
    "Note that you can always extract the actual numbers from a called to your dataset using `.values` at the end. Be careful when you use this since it might be a lot of information. Always check the metadata without using `.values` first to see how large the arrays are you'll be reading in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a variable from ds.data_vars list. (put a variable name to replace  {var}\n",
    "thevar = \"HMXL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a variable (dataarray) (put a variable name to replace  {var}\n",
    "ds[thevar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual array data\n",
    "ds[thevar].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual array data\n",
    "ds[thevar].coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataarray attributes\n",
    "ds[thevar].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data\n",
    "\n",
    "Extract data from `xarray` datasets using `.sel` and `.isel`. `.sel` uses variable names, `.isel` uses integer index values for the dimension. \n",
    "\n",
    "When files are read in, data arrays are read in as variables and the coordinates that they are in reference to are called \"coordinates\". For example, in the present dataset, we have the following coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have the following data variables, which are the main data of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should subselect from a data variable with respect to the coordinates. We can select from none up to all of the coordinates that the variable is respect to. In the following cell, the coordinates for the selected variable are indicated with an asterisk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.{datavar}.coords\n",
    "ds[thevar].coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by label \n",
    "\n",
    "\n",
    "The `.sel()` method is the primary access method for **purely coordinate label based indexing.**. The following are valid inputs:\n",
    "\n",
    "- A single coordinate label e.g. `time=\"2021-03-01\"`\n",
    "- A list or array of coordinate labels `time=[=\"2021-01-01\", =\"2021-03-10\", =\"2021-03-12\"]`\n",
    "- A slice object with coordinate labels e.g. `time=slice(\"2021-01-01\", \"2021-03-01\")`.  (Note that contrary to usual Python slices, both the start and the stop are included, when present in the index!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a small example: let's plot a data series with a single coordinate. \n",
    "Choose one of the coordinates to select on and substitute for {thecoord} in the cell below.\n",
    "\n",
    "if the variable is a floating point number, its useful to use method=\"nearest\" to avoid precision problems. See the [xarray documentation](https://xarray.pydata.org/en/stable/generated/xarray.DataArray.sel.html) for more on usage of `method` and `tolerance` parameters in `.sel()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds[thevar].sel({thecoord}=7.151e+05,  method=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot it! \n",
    "This plot assumes the x axis is longitude the y axis is latitude. Substitute the appropriate coordinate names from your data for {long} and {lat}. Use the selection from the previous cell as the independent variable.\n",
    "\n",
    "Note that we are using `cartopy` to plot our maps and need to input the projection information (proj variable) for the projection appropriate to the dataset,  with the \"transform\" keyword argument to convert to PlateCarre projection (pc), which maps meridians to vertical straight lines of constant spacing, and circles of latitude to horizontal straight lines of constant spacing.\n",
    "\n",
    "Documentation on functions used here:\n",
    "\n",
    "[matplotlib pyplot module](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html)\n",
    "\n",
    "[cartopy](https://scitools.org.uk/cartopy/docs/latest/reference/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = cartopy.crs.Mollweide(central_longitude=180)\n",
    "pc = cartopy.crs.PlateCarree()\n",
    "#plt is matplotlib pyplot module\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "mappable = ax.contourf(ds.TLONG, ds.TLAT, ds[thevar].sel(time=7.151e+05,  method=\"nearest\"), 10,  transform=pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another approach to generating plots: \n",
    "## Basic plotting with via `.plot()`\n",
    "\n",
    "Xarray provides a `.plot()` method on `DataArray` and `Dataset`. This method is a wrapper around Matplotlib's `matplotlib.pyplot.plot()`. xaarray will automatically guess the type of plot based on the dimensionality of the data. By default `.plot()` creates:\n",
    "\n",
    "- a **line** plot for `1-D arrays` using `matplotlib.pyplot.plot()`\n",
    "- a **pcolormesh** plot for 2-D arrays using `matplotlib.pyplot.pcolormesh()`\n",
    "- a **histogram** for everything else (more than 2 dimensions) using `matplotlib.pyplot.hist()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the long and latitude by array index integers:\n",
    "ds[thevar].isel(nlon=3,nlat=6).plot(marker=\"o\", size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[thevar].isel(nlon=3).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either select by coordinate type, such as in the following cell where we choose all times between (and including) the years 1900 and 1950, longtitudes between 260 and 280 degrees, and latitude between 16 and 30 degrees. (substitute appropriate variable names for you dataset and uncomment to test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.{variable}.sel(time=slice('1900','1950'), lon=slice(-100+360, -80+360), lat=slice(30,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".... or by index, such as in the following cell where we select the first index of data in terms of with time, longitude, and latitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.{variable}.isel(time=0, lon=0, lat=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations\n",
    "\n",
    "You can do basic operations using `xarray`, such as take the mean. You can input the axis or axises you want to take the operation over in the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsp[{variable}].mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds[{variable}].sum(('lat','lon'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THREDDS example. Loading data from a remote dataset.\n",
    "\n",
    "The netCDF library can be compiled such that it is 'THREDDS enabled', which means that you can put in a URL instead of a filename. This allows access to large remote datasets, without having to download the entire file. You can find a large list of datasets served via an OpenDAP/THREDDs server [here](http://apdrc.soest.hawaii.edu/data/data.php).\n",
    "\n",
    "Let's look at the ESRL/NOAA 20th Century Reanalysis – Version 2. You can access the data by the following link (this is the link of the `.dds` and `.das` files without the extension.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'http://apdrc.soest.hawaii.edu/dods/public_data/Reanalysis_Data/NOAA_20th_Century/V2c/daily/monolevel/cprat'\n",
    "ds2 = xr.open_dataset(loc)\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2['cprat'].long_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = cartopy.crs.Sinusoidal(central_longitude=180)\n",
    "\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "ax.coastlines(linewidth=0.25)\n",
    "# use the last time available\n",
    "mappable = ax.contourf(ds2.lon, ds2.lat, ds2.cprat.isel(time=-1), 20, cmap=cmo.tempo, transform=pc)\n",
    "ax.set_title(pd.Timestamp(ds2.time[-1].values).isoformat()[:10])  # or use .strftime instead of .isoformat\n",
    "fig.colorbar(mappable).set_label('%s' % ds2['cprat'].long_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also just plot against the included coordinates with built-in convenience functions (this is analogous to `pandas` which was for one dimension). The sst is being plotted against longitude and latitude, which is flattening it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.sel(time='1954-6-1').plot()#transform=pc)  # the plot's projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = cartopy.crs.Mollweide(central_longitude=180)\n",
    "fig = plt.figure(figsize=(14,6))\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "ds.sst.sel(time='1954-6-1').plot(transform=pc)  # the plot's projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy\n",
    "\n",
    "You can use the `groupby` method to do some neat things. Let's group by an attribute {attribute} on a variable {var} and save a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some_mean = ds.groupby('{var}.{attribute}').mean('{var}')\n",
    "#some_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving NetCDF files\n",
    "\n",
    "Creating netCDF files is tedious if doing it from scratch, but it is very easy when starting from data that has been read in using `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'test.nc'\n",
    "some_mean.to_netcdf(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
